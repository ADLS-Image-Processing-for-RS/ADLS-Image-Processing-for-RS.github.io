{
  "hash": "291ddebc0846ff6fdf9617ba500e091b",
  "result": {
    "engine": "knitr",
    "markdown": "---\necho: true\n---\n\n\n\n\n# Feature Engineering {#sec-feature-engineering}\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n## What is Feature Engineering?\n\n- Feature Engineering is the process of using domain knowledge to extract features from raw data.\n- This is especially useful, when our raw data is not sufficient to build a model\n- In our previous example, we only had luminosity to predict the class of the raster cells\n- As discussed in the chapter @sec-feature-engineering0, we humans ourselves rely on context to determine the land cover types\n- This context is provided by the values of the sorrounding pixels\n- We can provide this context by applying focal filters to the raster data\n\n\n## Focal filters\n\n\n\n- Focal Filters, as we have seen in the chapter @sec-focal-1, aggregate the values over a (moving) neighborhood of pixels. \n- We can determine the size and shape of this neighborhood by specifying a matrix\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 5\nfocal3by3 <- matrix(rep(1,n^2), ncol = n)\n\nr_foc3 <- focal(ces1961, focal3by3, fun = sd, fillNA = TRUE)\n\nr_foc3 <- r_foc3\n\n# plot(r_foc3)\n```\n:::\n\n::: {.cell layout-nrow=\"1\"}\n::: {.cell-output-display}\n![The original raster](lesson4-2-feature-engineering_files/figure-html/fig-focal-filter-1.png){#fig-focal-filter-1 width=672}\n:::\n\n::: {.cell-output-display}\n![The raster after applying a focal filter](lesson4-2-feature-engineering_files/figure-html/fig-focal-filter-2.png){#fig-focal-filter-2 width=672}\n:::\n:::\n\n\n\n\n\n\n## Using focal filters as features\n\n- To use the focal filters as features, the values of the focal filters need to be normalized to [0,1]\n- A simple way to do this is to use the [min-max normalization](https://en.wikipedia.org/wiki/Feature_scaling#Rescaling_(min-max_normalization)): \n\n$$x' = \\frac{x - min(x)}{\\max(x) - min(x)}$$\n\n\n- To implement this in R, we need to use `global(x, min)` or (slightly faster) `minmax(x)`. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nminmax_normalization <- function(x){\n  minmax_vals <- minmax(x)[,1]\n  minval <- minmax_vals[1]\n  maxval <- minmax_vals[2]\n  \n  (x-minval)/(maxval-minval)\n}\n\nr_foc3 <- minmax_normalization(r_foc3)\n\nces <- c(ces1961, r_foc3)\n\nnames(ces) <- c(\"luminosity\", \"focal3by3\")\n```\n:::\n\n\n\n\n\n\n## Feature extraction\n\n- Just as we did in our first approach (see @sec-feature-extraction1), we need to extract the features from the raster data at the labelled points\n- Note that the resulting data frame now has two columns, rather than just a single column\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_features_b <- terra::extract(ces, data_train, ID = FALSE)\n\nhead(train_features_b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  luminosity focal3by3\n1  0.1843137 0.1800299\n2  0.3568627 0.2273958\n3  0.1960784 0.2349411\n4  0.4392157 0.1740047\n5  0.6313725 0.1663846\n6  0.2823529 0.3338187\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_train2_b <- cbind(data_train, train_features_b) |> \n  st_drop_geometry()\n```\n:::\n\n\n\n\n\n## Train the model\n\n- Just as in our first approach (see @sec-training-model1), we need to train the model\n- This time, we have more features to train the model\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncart_modelb <- rpart(class~., data = data_train2_b, method = \"class\")\n\nlibrary(rpart.plot)\nrpart.plot(cart_modelb, type = 3)\n```\n\n::: {.cell-output-display}\n![](lesson4-2-feature-engineering_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## Predict the classes\n\nSee @sec-prediction-per-class and @sec-highest-probability-class.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Probability per class\nces1961_predictb <- predict(ces, cart_modelb)\n\n# Class with highest probability\nces1961_predict2b <- which.max(ces1961_predictb)\n```\n:::\n\n\n\n\n\n## Evaluate the model\n\nSee @sec-model-evaluation-1 and @sec-model-evaluation-2\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_featuresb <- terra::extract(ces1961_predict2b, data_test, ID = FALSE)\n\nconfusion_matrixb <- cbind(data_test, test_featuresb) |> \n  st_drop_geometry() |> \n  transmute(predicted = class.1, actual = class) |> \n  table()\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"4\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Actual</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:right;\"> Agriculture </th>\n   <th style=\"text-align:right;\"> Buildings </th>\n   <th style=\"text-align:right;\"> Forest </th>\n   <th style=\"text-align:right;\"> Shadows </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Agriculture </td>\n   <td style=\"text-align:right;background-color: red !important;\"> 37 </td>\n   <td style=\"text-align:right;background-color: white !important;\"> 3 </td>\n   <td style=\"text-align:right;background-color: white !important;\"> 9 </td>\n   <td style=\"text-align:right;background-color: white !important;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Buildings </td>\n   <td style=\"text-align:right;background-color: white !important;\"> 2 </td>\n   <td style=\"text-align:right;background-color: red !important;\"> 5 </td>\n   <td style=\"text-align:right;background-color: white !important;\"> 0 </td>\n   <td style=\"text-align:right;background-color: white !important;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Forest </td>\n   <td style=\"text-align:right;background-color: white !important;\"> 2 </td>\n   <td style=\"text-align:right;background-color: white !important;\"> 1 </td>\n   <td style=\"text-align:right;background-color: red !important;\"> 29 </td>\n   <td style=\"text-align:right;background-color: white !important;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> Shadows </td>\n   <td style=\"text-align:right;background-color: white !important;\"> 0 </td>\n   <td style=\"text-align:right;background-color: white !important;\"> 0 </td>\n   <td style=\"text-align:right;background-color: white !important;\"> 1 </td>\n   <td style=\"text-align:right;background-color: red !important;\"> 20 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n- In our first approach, we achieved an accuracy of *0.67* (see @sec-model-evaluation-1)\n- With our additional features, the overall accuracy is *0.83*\n- We can further improve our modle by adding more features in this way",
    "supporting": [
      "lesson4-2-feature-engineering_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}