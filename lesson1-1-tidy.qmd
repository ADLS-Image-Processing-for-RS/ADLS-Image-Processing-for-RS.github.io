
# From tabular data to raster {#sec-tidy-to-raster}


```{r}
#| echo: false

library(readr)
library(dplyr)
library(ggplot2)
library(kableExtra)
library(tidyr)
library(scales)
library(tibble)
library(gt)
library(abind)

```



## Tabular data

- @wickham2014: Tidy tabular data: Each variable is a column, each observation is a row, and each type of observational unit
is a table.
- Below is a dataset from @baltagi2008
- *Observation* is a state in a particular year
- *Variable* is a measured parameter (see below)

:::{.notes}
- Start with Wickham's fundamental definition - this is the foundation
- Emphasize this is about data structure, not just organization
- The Produc dataset is a classic econometric panel dataset - good for demonstrating concepts
- Make sure students understand what constitutes an "observation" vs a "variable"
:::



:::{.callout-note collapse="true"}

## Parameter

- pcap: public capital stock
- hwy: highway and streets
- water: water and sewer facilities
- util: other public buildings and structures
- pc: private capital stock
- gsp: gross state product
- emp: labor input measured by the employment in non–agricultural payrolls
- unemp: state unemployment rate
:::



```{r}
#| echo: true
#| code-fold: false

Produc <- read_csv("data/Produc.csv") |> 
    select(-region) |> 
    filter(!(state == "ARIZONA" & year == 1971))

# Produc[Produc$state == "ARIZONA" & Produc$year == 1971,c("unemp")] <- NA

Produc |> 
    head() |> 
    kable()


```


:::{.callout-note .notes collapse="true"}
- This is considered a *long* table and is great for modelling and visualization.
- It's bad for memory (a lot of repetitions)
:::



## Long tables have a lot of repetitions:

```{r}
#| echo: true
#| code-fold: false
#| collapse: true
length(Produc$state)
n_distinct(Produc$state)

length(Produc$year)
n_distinct(Produc$year)


n_values <- dim(Produc) |>
  prod()

n_values
```

:::{.notes}
- Walk through the calculation step by step
- 816 total entries for state, but only 48 unique states
- This repetition is characteristic of long/tidy format
- Great for analysis but wasteful of memory
- This leads naturally to why we might want wide format for raster data
:::



## Wide tables have less repetitions.

To demonstrate we convert a long to wide.

:::{.notes}
- This is the key transition - from statistical/analysis format to raster format
- Wide format is more memory efficient but less flexible for analysis
- This mirrors how raster data is naturally stored
:::


```{r}
#| echo: true
#| code-fold: false

# Pivoting must be done per variable
Produc_wide <- Produc |> 
    select(state, year, unemp) |> 
    pivot_wider(names_from = state, values_from = unemp) |> 
    column_to_rownames("year")


```


:::{.callout-note .notes collapse="true"}

We can either omit the column "year", (since this is implicit knowledge, $row_i + 1970$), or use it as a `rowname`.
:::



## Long vs Wide 

Long / tidy:
```{r}
#| echo: true
#| code-fold: false
Produc |> 
    head(5) |> 
    kable()
```

<hr>

Wide / untidy:

```{r}
#| echo: true
#| code-fold: false
Produc_wide |> 
    head(5) |> 
    kable()

```







## Dataframe → Matrix

Less repetitions / smaller memory footprint is only part of the advantage:

- All columns now have the same datatype (`dbl`)
  - This means, they can be stored in a matrix / array
  - This gives us a *big* speed advantage (see @fig-benchmark)

```{r}
#| echo: false
#| label: fig-benchmark

Produc_matrix <- as.matrix(Produc_wide)

rownames(Produc_matrix) <- 1970:1986

bm <- bench::mark(
    matrix = mean(Produc_matrix, na.rm = TRUE),
    dataframe = mean(Produc_wide |> unlist(),na.rm = TRUE),
    filter_gc = FALSE
)

autoplot(bm)


```


:::{.notes}
- Homogeneous data types enable matrix operations
- Matrices are stored contiguously in memory - much faster access
- This speed difference becomes enormous with large raster datasets
- Matrix operations are highly optimized and often vectorized
:::


## Limitations

- Matrices are only advantageous if they are *densely* populated (little `NA`s)
- Speed and memory footprint is only relevant if the data is large

:::{.notes}
- If data is mostly missing, wide format can be wasteful
- For small datasets, the overhead isn't worth it
- Remote sensing data is typically large and dense - perfect for this approach
- This sets up why raster format is natural for imagery
:::


